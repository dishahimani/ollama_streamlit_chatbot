This is chatbot built using llama3 and streamlit

Steps to follow:

1) Download Ollama locally
2) Download desired Ollama model (here llama3) by: Ollama Pull <model_name>
3) Test and run model locally in background with: Ollama run <model_name>, Here run: Ollama run llama3
4) Now download requirements for the project by: pip install -r requirements.txt
5) Run the streamlit application with this command: python -m streamlit run ollama_chatbot.py   
